{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sLkiaa1nE0TP"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question1 solution"
      ],
      "metadata": {
        "id": "-OGgfgR_HRI7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class IrisDataProcessor:\n",
        "    def __init__(self):\n",
        "        self.data = load_iris()\n",
        "        self.df = None\n",
        "        self.X_train = None\n",
        "        self.X_test = None\n",
        "        self.y_train = None\n",
        "        self.y_test = None\n",
        "        self.scaler = StandardScaler()\n",
        "\n",
        "    def prepare_data(self):\n",
        "        self.df = pd.DataFrame(self.data.data, columns=self.data.feature_names)\n",
        "        self.df['target'] = self.data.target\n",
        "\n",
        "        print(self.df.shape)\n",
        "        features = self.df.drop(columns=['target'])\n",
        "        scaled_features = self.scaler.fit_transform(features)\n",
        "        self.df[features.columns] = scaled_features\n",
        "\n",
        "        X = self.df.drop(columns=['target'])\n",
        "        y = self.df['target']\n",
        "\n",
        "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "        print(\"Training set shape:\", self.X_train.shape)\n",
        "        print(\"Test set shape:\", self.X_test.shape)\n",
        "\n",
        "    def get_feature_stats(self):\n",
        "        return self.df.describe()"
      ],
      "metadata": {
        "id": "lytKyu8uF8Xk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processor = IrisDataProcessor()\n",
        "processor.prepare_data()\n",
        "feature_stats = processor.get_feature_stats()\n",
        "print(feature_stats)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAd2E34xF--B",
        "outputId": "6e5fb3f7-a194-4de9-fee2-4242bcb2c314"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(150, 5)\n",
            "Training set shape: (120, 4)\n",
            "Test set shape: (30, 4)\n",
            "       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
            "count       1.500000e+02      1.500000e+02       1.500000e+02   \n",
            "mean       -1.468455e-15     -1.823726e-15      -1.610564e-15   \n",
            "std         1.003350e+00      1.003350e+00       1.003350e+00   \n",
            "min        -1.870024e+00     -2.433947e+00      -1.567576e+00   \n",
            "25%        -9.006812e-01     -5.923730e-01      -1.226552e+00   \n",
            "50%        -5.250608e-02     -1.319795e-01       3.364776e-01   \n",
            "75%         6.745011e-01      5.586108e-01       7.627583e-01   \n",
            "max         2.492019e+00      3.090775e+00       1.785832e+00   \n",
            "\n",
            "       petal width (cm)      target  \n",
            "count      1.500000e+02  150.000000  \n",
            "mean      -9.473903e-16    1.000000  \n",
            "std        1.003350e+00    0.819232  \n",
            "min       -1.447076e+00    0.000000  \n",
            "25%       -1.183812e+00    0.000000  \n",
            "50%        1.325097e-01    1.000000  \n",
            "75%        7.906707e-01    2.000000  \n",
            "max        1.712096e+00    2.000000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 3 solution"
      ],
      "metadata": {
        "id": "Vw0o9tG8NEZ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import joblib\n",
        "\n",
        "class IrisModelOptimizer:\n",
        "    def __init__(self, experiment):\n",
        "        self.experiment = experiment\n",
        "        iris = load_iris()\n",
        "        X, y = iris.data, iris.target\n",
        "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "        self.model = LogisticRegression(max_iter=200)\n",
        "\n",
        "    def quantize_model(self):\n",
        "        self.model.fit(self.X_train, self.y_train)\n",
        "        original_accuracy = accuracy_score(self.y_test, self.model.predict(self.X_test))\n",
        "        self.model.coef_ = np.round(self.model.coef_, decimals=2)\n",
        "        self.model.intercept_ = np.round(self.model.intercept_, decimals=2)\n",
        "\n",
        "        quantized_accuracy = accuracy_score(self.y_test, self.model.predict(self.X_test))\n",
        "        joblib.dump(self.model, \"quantized_logistic_model.joblib\")\n",
        "\n",
        "        return original_accuracy, quantized_accuracy\n",
        "\n",
        "    def run_tests(self):\n",
        "        original_accuracy, quantized_accuracy = self.quantize_model()\n",
        "        print(\"Original Accuracy:\", original_accuracy)\n",
        "        print(\"Quantized Accuracy:\", quantized_accuracy)\n",
        "\n",
        "        loaded_model = joblib.load(\"quantized_logistic_model.joblib\")\n",
        "        test_accuracy = accuracy_score(self.y_test, loaded_model.predict(self.X_test))\n",
        "        print(\"All tests passed successfully\")\n",
        "\n",
        "\n",
        "experiment_name = \"LogisticRegression_Iris_Quantization\"\n",
        "optimizer = IrisModelOptimizer(experiment_name)\n",
        "optimizer.run_tests()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPLK7V9_Jc6n",
        "outputId": "c197a925-5b7c-41cc-e9c8-1900ee18c5ca"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Accuracy: 1.0\n",
            "Quantized Accuracy: 1.0\n",
            "All tests passed successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9zxxGJWEN7Bw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}