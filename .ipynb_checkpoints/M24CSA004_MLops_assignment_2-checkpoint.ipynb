{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {
    "id": "ip8P6Easu99f"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, TargetEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {
    "id": "KJBObtzHvbzx"
   },
   "outputs": [],
   "source": [
    "# !wget https://archive.ics.uci.edu/static/public/275/bike+sharing+dataset.zip\n",
    "# !unzip bike+sharing+dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "MZO5X7UTvTsh",
    "outputId": "c7f75d3a-fd8b-4ce3-e4d0-afad02630468"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant      dteday  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
       "0        1  2011-01-01       1   0     1   0        0        6           0   \n",
       "1        2  2011-01-01       1   0     1   1        0        6           0   \n",
       "2        3  2011-01-01       1   0     1   2        0        6           0   \n",
       "3        4  2011-01-01       1   0     1   3        0        6           0   \n",
       "4        5  2011-01-01       1   0     1   4        0        6           0   \n",
       "\n",
       "   weathersit  temp   atemp   hum  windspeed  casual  registered  cnt  \n",
       "0           1  0.24  0.2879  0.81        0.0       3          13   16  \n",
       "1           1  0.22  0.2727  0.80        0.0       8          32   40  \n",
       "2           1  0.22  0.2727  0.80        0.0       5          27   32  \n",
       "3           1  0.24  0.2879  0.75        0.0       3          10   13  \n",
       "4           1  0.24  0.2879  0.75        0.0       0           1    1  "
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('hour.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MMsewMp_yJ6m",
    "outputId": "9c2b3374-5747-4e88-c2b9-38fb34ef56cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['instant', 'dteday', 'season', 'yr', 'mnth', 'hr', 'holiday', 'weekday',\n",
       "       'workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed',\n",
       "       'casual', 'registered', 'cnt'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17379, 17)"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"http://localhost:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_description = {\n",
    "    \"dataset_name\": \"Bike Sharing Dataset\",\n",
    "    \"num_rows\": 17379,  # Example\n",
    "    \"num_features\": 18  # Example\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {
    "id": "8F9QmKHevYYz"
   },
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "\n",
    "    df = df.drop(['instant', 'casual', 'registered'], axis=1)\n",
    "\n",
    "\n",
    "    df['dteday'] = pd.to_datetime(df.dteday)\n",
    "\n",
    "    df['season'] = df.season.astype('category')\n",
    "    df['holiday'] = df.holiday.astype('category')\n",
    "    df['weekday'] = df.weekday.astype('category')\n",
    "    df['weathersit'] = df.weathersit.astype('category')\n",
    "    df['workingday'] = df.workingday.astype('category')\n",
    "    df['mnth'] = df.mnth.astype('category')\n",
    "    df['yr'] = df.yr.astype('category')\n",
    "\n",
    "\n",
    "    df['hour_temp_combination'] = df['hr'] * df['temp']\n",
    "    df['week_of_year'] = df['dteday'].dt.isocalendar().week\n",
    "    df['day_night'] = df['hr'].apply(lambda x: 'day' if 6 <= x <= 18 else 'night')\n",
    "    df['hour_categorical'] = pd.cut(df['hr'], bins=[0, 6, 12, 18, 24], labels=['Night', 'Morning', 'Afternoon', 'Evening'])\n",
    "    df['temp_hum_combination'] = df['temp'] * df['hum']\n",
    "\n",
    "    df = df.drop(columns=['dteday'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {
    "id": "E32SrarK6TXy"
   },
   "outputs": [],
   "source": [
    "def filter_columns(filter_list, df):\n",
    "    return df.filter(items=filter_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {
    "id": "cJlc_jmdyssg"
   },
   "outputs": [],
   "source": [
    "def plot_correlation_matrix_num_features(df):\n",
    "\n",
    "    numerical_cols = df.select_dtypes(include=['float64', 'int64','UInt32']).columns\n",
    "    corr_matrix = df[numerical_cols].corr()\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', linewidths=0.5)\n",
    "    plt.title('Correlation Matrix')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {
    "id": "u6SH3IM_zknp"
   },
   "outputs": [],
   "source": [
    "def input_output_features(df):\n",
    "\n",
    "    X = df.drop(columns=['cnt']) # Features\n",
    "    y = df['cnt'] # Target\n",
    "\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {
    "id": "iV2Pjcylz3Lg"
   },
   "outputs": [],
   "source": [
    "\n",
    "def data_preprocessing(X, numerical_features, categorical_features, y):\n",
    "\n",
    "\n",
    "    # Numerical features\n",
    "    numerical_pipeline = Pipeline([\n",
    "                                    ('imputer', SimpleImputer(strategy='mean')), # Impute missing values with mean\n",
    "                                    ('scaler', MinMaxScaler()) # Normalize using MinMaxScaler\n",
    "                                  ])\n",
    "\n",
    "    X[numerical_features] = numerical_pipeline.fit_transform(X[numerical_features])\n",
    "\n",
    "    # Categorical features for One Hot Encoding\n",
    "    categorical_pipeline = Pipeline([\n",
    "                                      ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                                      ('onehot', OneHotEncoder(sparse_output=False, drop='first'))\n",
    "                                    ])\n",
    "    \n",
    "    # Categorical features for Target Encoding\n",
    "    # categorical_pipeline = Pipeline([\n",
    "    #                                   ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    #                                   ('target_encoder', TargetEncoder(smooth=\"auto\"))\n",
    "    #                                 ])\n",
    "\n",
    "    # Transforming above OHE\n",
    "    X_encoded = categorical_pipeline.fit_transform(X[categorical_features])\n",
    "    X_encoded = pd.DataFrame(X_encoded,columns=categorical_pipeline.named_steps['onehot'].get_feature_names_out(categorical_features))\n",
    "    # Encoded categorical features + Numerical features\n",
    "    X = pd.concat([X.drop(columns=categorical_features), X_encoded], axis=1)\n",
    "\n",
    "    # Transforming categorical features using Target Encoder\n",
    "    # X.columns = X.columns.astype(str)\n",
    "    # X_encoded = categorical_pipeline.fit_transform(X[categorical_features], y=y)\n",
    "    # print(X_encoded.shape)\n",
    "    # X_encoded = pd.DataFrame(categorical_pipeline.named_steps['target_encoder'].get_feature_names_out(categorical_features))\n",
    "    # X = pd.concat([X.drop(columns=categorical_features), X_encoded], axis=1)\n",
    "    # X = X.drop(columns=0)\n",
    "    # print(X.columns)\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {
    "id": "4IellE7B6Ckm"
   },
   "outputs": [],
   "source": [
    "def evaluation_metrics(y_test, y_pred):\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    return mse, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionFromScratch:\n",
    "\n",
    "    def __init__(self, learning_rate, n_iterations):\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "        self.bias = None\n",
    "        self.weights = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "\n",
    "        # Gradient descent iterations\n",
    "        for _ in range(self.n_iterations):\n",
    "            # Predict using current weights\n",
    "            y_predicted = X @ self.weights + self.bias\n",
    "\n",
    "            # Calculate gradients\n",
    "            dw = (1 / n_samples) * X.T @ (y_predicted - y)\n",
    "            db = (1 / n_samples) * np.sum(y_predicted - y)\n",
    "\n",
    "            # Update weights and bias\n",
    "            self.weights -= self.learning_rate * dw\n",
    "            self.bias -= self.learning_rate * db\n",
    "\n",
    "    def predict(self, X):\n",
    "        print(self.weights, self.bias)\n",
    "        return X @ self.weights + self.bias\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yIPRTxgs4fXt",
    "outputId": "117a1bac-2f55-413a-dda8-f6734b9e04ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['season', 'yr', 'mnth', 'hr', 'holiday', 'weekday', 'workingday',\n",
      "       'weathersit', 'temp', 'atemp', 'hum', 'windspeed', 'cnt',\n",
      "       'hour_temp_combination', 'week_of_year', 'day_night',\n",
      "       'temp_hum_combination'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = feature_engineering(df)\n",
    "\n",
    "filter_list = ['season', 'yr', 'mnth', 'hr', 'holiday', 'weekday', 'workingday',\n",
    "                'weathersit', 'temp', 'atemp', 'hum', 'windspeed', 'cnt',\n",
    "                'hour_temp_combination', 'week_of_year', 'day_night',\n",
    "                 'temp_hum_combination'] #'hour_categorical','day_night'\n",
    "\n",
    "filtered_df = filter_columns(filter_list, df)\n",
    "print(filtered_df.columns)\n",
    "\n",
    "# plot_correlation_matrix_num_features(df)\n",
    "\n",
    "X,y = input_output_features(filtered_df)\n",
    "\n",
    "\n",
    "numerical_features = ['temp', 'hum','windspeed']\n",
    "categorical_features = ['season', 'weathersit', 'day_night']\n",
    "X = data_preprocessing(X, numerical_features, categorical_features,y )\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=42)\n",
    "\n",
    "\n",
    "# Start an MLflow experiment\n",
    "with mlflow.start_run(run_name=\"Linear Regressor Model built from scratch with one hot encoding and old features\"):\n",
    "\n",
    "    for key, value in dataset_description.items():\n",
    "        mlflow.log_param(key, value)\n",
    "\n",
    "    model = LinearRegressionFromScratch(learning_rate=0.0001, n_iterations=500)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    #### Linear Regression ########\n",
    "    # params = {\n",
    "    #             \"fit_intercept\": model.fit_intercept\n",
    "    # }\n",
    "\n",
    "    # # Log Parameters\n",
    "    # mlflow.log_param(\"fit_intercept\", model.fit_intercept)\n",
    "\n",
    "    #### Random Forest Regression ########\n",
    "    # params = {\n",
    "    # \"n_estimators\": model.n_estimators,\n",
    "    # \"max_depth\": model.max_depth,\n",
    "    # \"min_samples_split\": model.min_samples_split,\n",
    "    # \"min_samples_leaf\": model.min_samples_leaf,\n",
    "    # \"max_features\": model.max_features,\n",
    "    # \"bootstrap\": model.bootstrap,\n",
    "    # \"random_state\": model.random_state\n",
    "    # }\n",
    "    # # Log Parameters\n",
    "    # mlflow.log_param(\"n_estimators\", model.n_estimators)\n",
    "    # mlflow.log_param(\"max_depth\", model.max_depth)\n",
    "    # mlflow.log_param(\"min_samples_split\", model.min_samples_split)\n",
    "    # mlflow.log_param(\"min_samples_leaf\", model.min_samples_leaf)\n",
    "    # mlflow.log_param(\"max_features\", model.max_features)\n",
    "    # mlflow.log_param(\"bootstrap\", model.bootstrap)\n",
    "    # mlflow.log_param(\"random_state\", model.random_state)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"Number of NaN in y_test:\", np.isnan(y_test).sum())\n",
    "    print(y_pred)\n",
    "\n",
    "    mse, r2 = evaluation_metrics(y_test, y_pred)\n",
    "    print(f\"Mean Squared Error: {mse}\")\n",
    "    print(f\"R-squared: {r2}\")\n",
    "\n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"mse\", mse)\n",
    "    mlflow.log_metric(\"r2\", r2)\n",
    "\n",
    "    # Log the model\n",
    "    mlflow.sklearn.log_model(model, \"model\")\n",
    "\n",
    "    print(f\"Model saved in run {mlflow.active_run().info.run_uuid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "olj_eDyL-n_u"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
